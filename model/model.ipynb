{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c370820d-ed7e-494a-bfdc-06c3266ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249221bd-8421-4132-a718-b69ba7731469",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c68b1-cc93-4d52-bd24-b9875cfed1a2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Preprocessing of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e4d007-427b-4bbe-abe8-437d9cba5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaedf56f-1510-4db5-b59c-5b0f69bfb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the  base64 img from file\n",
    "\n",
    "def load_base64_img():\n",
    "    with open('img.txt') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c6b4ed-e265-455f-b4a5-1ffd0e73cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the base64 image/ image path --> transparent image to white background ---> to array using cv2\n",
    "\n",
    "def get_cv2_image_from_base64_string(b64str, img_path):\n",
    "    if img_path:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    else:\n",
    "        encoded_data = b64str.split(',')[1]\n",
    "        nparr = np.frombuffer(base64.b64decode(encoded_data), np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED) # load the image with alpha channel\n",
    "        \n",
    "    \n",
    "    ## transparent to white bg \n",
    "    alpha_channel = img[: ,: , 3]\n",
    "    _, mask = cv2.threshold(alpha_channel, 254, 255, cv2.THRESH_BINARY) # binarize mask\n",
    "    color = img[: ,: ,: 3]\n",
    "    new_img = cv2.bitwise_not(cv2.bitwise_not(color, mask = mask))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea681352-e7b4-4725-8af7-7066a3df9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing the image into 28x28 pixels\n",
    "\n",
    "def get_img_reshape_by_cv2(img_data):\n",
    "    image = img_data\n",
    "    grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY) # convert to gray\n",
    "    ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    preprocessed_digits = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        roi = cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=1)\n",
    "\n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit = thresh[y:y+h, x:x+w]\n",
    "\n",
    "        # Resizing that digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (100,100))\n",
    "        resized_digit = cv2.resize(resized_digit, (50,50))\n",
    "        resized_digit = cv2.resize(resized_digit, (40,40))\n",
    "        resized_digit = cv2.resize(resized_digit, (25,25))\n",
    "        resized_digit = cv2.resize(resized_digit, (18,18)) ##### <------\n",
    "\n",
    "        # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "\n",
    "        # Adding the preprocessed digit to the list of preprocessed digits\n",
    "        preprocessed_digits.append(padded_digit)\n",
    "\n",
    "    # plt.imshow(padded_digit, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    \n",
    "    # print(preprocessed_digits)\n",
    "    inp = np.array(preprocessed_digits)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633a2f0-31ae-4604-8fab-5a3fc1da2bae",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Preprocessing of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b7314a6b-a427-455d-b088-d4cb7691748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path of dataset and cropped img\n",
    "\n",
    "path_to_data = \"./dataset/\"\n",
    "path_to_cropped = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2a8d6988-0873-4bef-8f04-452f82fde51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "if os.path.exists(path_to_cropped):\n",
    "    shutil.rmtree(path_to_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "55609c5b-ea19-49d8-abd9-eeff41ee79ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/0',\n",
       " './dataset/1',\n",
       " './dataset/2',\n",
       " './dataset/4',\n",
       " './dataset/5',\n",
       " './dataset/6',\n",
       " './dataset/7',\n",
       " './dataset/8',\n",
       " './dataset/9']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the digits image dir from the dataset into the list\n",
    "\n",
    "import os\n",
    "img_dirs = []\n",
    "\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)\n",
    "\n",
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "da984bea-e4cd-415d-a89a-345b6168199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the cropped img folder is present or not\n",
    "\n",
    "if os.path.exists(path_to_cropped):\n",
    "    shutil.rmtree(path_to_cropped)\n",
    "os.mkdir(path_to_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2cea586a-7ce2-4481-933f-2394ac557e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cropped digit_img folder:  ./dataset/cropped/0\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/1\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/2\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/4\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/5\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/6\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/7\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/8\n",
      "Generating cropped digit_img folder:  ./dataset/cropped/9\n",
      "\n",
      "Succesfully Completed! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# cropping the dataset digit images\n",
    "\n",
    "crop_img_dirs = []\n",
    "digit_dict = {}\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1    \n",
    "    digit = (img_dir.split('/')[-1])\n",
    "    digit_dict[digit]=[]\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        url = entry.path\n",
    "        \n",
    "        img_b64_transp = get_cv2_image_from_base64_string(None, url)\n",
    "        # print(img_b64_transp)\n",
    "        \n",
    "        reshape_img = get_img_reshape_by_cv2(img_b64_transp)\n",
    "        crop_digit = reshape_img\n",
    "        \n",
    "        # print(crop_digit[0])\n",
    "        # plt.imshow(crop_digit[0])\n",
    "        if crop_digit is not None:\n",
    "            crop_img_folder = path_to_cropped + digit\n",
    "            if not os.path.exists(crop_img_folder):\n",
    "                print(\"Generating cropped digit_img folder: \", crop_img_folder)\n",
    "                os.mkdir(crop_img_folder)\n",
    "                crop_img_dirs.append(crop_img_folder)\n",
    "            \n",
    "            crop_file_name = digit + \"_\" + str(count) + \".png\"\n",
    "            crop_file_path = crop_img_folder + \"/\" + crop_file_name\n",
    "            \n",
    "            \n",
    "            cv2.imwrite(crop_file_path, crop_digit[0])\n",
    "            digit_dict[digit].append(crop_file_path)\n",
    "            count+=1\n",
    "print(\"\\nSuccesfully Completed! ðŸ˜Š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e7758eba-7413-4813-862e-dfb4a4e902a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/cropped/0\\\\0_1.png',\n",
       " './dataset/cropped/0\\\\0_10.png',\n",
       " './dataset/cropped/0\\\\0_11.png',\n",
       " './dataset/cropped/0\\\\0_12.png',\n",
       " './dataset/cropped/0\\\\0_13.png']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending the file path of each of the digit image in the dictinary\n",
    "\n",
    "digit_dict = {}\n",
    "\n",
    "for img_dir in crop_img_dirs:\n",
    "    digit = img_dir.split(\"/\")[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    digit_dict[digit] = file_list\n",
    "\n",
    "digit_dict['0'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af5e79-9f17-49d3-9410-b4fa62a23d25",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Test, train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "67c73341-3491-470a-9313-64357ed86eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for digit, digit_img_path in digit_dict.items():\n",
    "    for training_img in digit_img_path:\n",
    "        img = cv2.imread(training_img)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        img=img/225.0\n",
    "        \n",
    "        img_rshp = img.reshape(28, 28, 3)    # reshape img into 1D\n",
    "        X.append(img)\n",
    "        y.append(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d088af28-6224-4af5-8933-5e42b9eda2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b3cc1d0a-7ff7-4298-ae2b-b1e7f1202a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "cbc9ae7d-7969-4206-94ac-268dd3f066a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "eb12b4fe-1853-4905-8265-9ef9acd0b032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 28)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "6d16ea79-1991-4f5e-b607-6956280ec635",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 453936 into shape (28,193)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [364]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      2\u001b[0m X\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 453936 into shape (28,193)"
     ]
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X[0]), len(X)).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9bbfb60f-ffef-4a3b-a030-5fb2c354f55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 3)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8dae2b7c-a2e6-4a80-bbcc-7205a1f357d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 784, 3)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "df199732-8620-4e18-aa1f-26eadb2d744c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2fef57c1-0e53-4f09-9283-41953dfabda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875795ea-6ad0-4521-966c-dc23b0ba14dc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8340ec20-ed7b-415d-82f2-4e1c2789e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0b3c360c-a25e-429b-9482-e8fdfebf2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e98ba468-997d-495d-a0df-0c7979814798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_11\" is incompatible with the layer: expected shape=(None, 28, 28), found shape=(None, 784, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [274]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Debjeet\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_11\" is incompatible with the layer: expected shape=(None, 28, 28), found shape=(None, 784, 3)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e68a73f8-24f9-4e7a-a31e-480272a1d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 679us/step - loss: 0.0766 - accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07661169767379761, 0.9749000072479248]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ae1b0-8399-4aa5-bb4e-5af36662c2c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Lets, now check how well our model performs by giving an actuall image as input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c3d0d6d9-4a1f-4f89-b35a-dcf71d8404a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600, 3)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img = get_cv2_image_from_base64_string(load_base64_img(), None)\n",
    "n_img.shape ## returns x, y, rbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "84361897-1ae9-42e3-b61d-720c86762d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29966e3fc40>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(n_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "007ae145-415d-451b-b8f9-6707498cdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img = get_img_reshape_by_cv2(n_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1360c4a2-bf7e-4312-86d2-d44b54420245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2995ea98fa0>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(crop_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b03b0a80-b7d8-417e-b4c0-30e2cfb5e03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "bba6345c-7066-4eb5-b6c7-d494397b7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(crop_img[1].reshape(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "afec7a20-913a-48a8-abe5-0be3309311b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bba913-5335-45cc-9963-9fc75a724921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
